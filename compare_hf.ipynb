{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952ed99",
   "metadata": {},
   "source": [
    "we first ask the model from transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2126a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I am gregarious and am incredibly lucky to have a great relationship with my best friend, and I am excited to discuss how I came to love him so much. His life was a whirlwind for me. I had to learn to live with my gut, my emotions, and my emotions.\\n\\nI started to love my friend with open eyes and a lot of hard work, but I also had to keep my mind open and focused on my own life. I am so grateful to have him with me. I will always love him. When I was a kid I was so embarrassed to have so many people around me, but now that I am in my 20s and I am seeing more and more people, I'm more open and open.\\n\\nAt the same time, I like him. I really want him to get through his transition to become an adult. I'm thrilled to have him. I will always love him. When I was a kid, I was so excited to have a big, happy family, but now, I'm sad to see my friends disappear like these, and I want them to get through their transition. I've been talking to a lot of people about this, and I'm so glad to hear they're okay, because it was always such a\"},\n",
       " {'generated_text': \"Hello, I am gregarious and polite. The question is, who are you and what is your purpose in life?\\n\\nSo, let me introduce you to the people who are your friends for life, and they are all here to be our friends. I am looking for people who are willing to share their stories, where they came from, where they are from, and have a passion for the work we do.\\n\\nIn this role, we are working on projects that meet the needs of our clients and our community. We are also exploring new opportunities for our clients to learn more about their industry, our communities, and how they can better contribute to their communities.\\n\\nOne of the most important things that I would like to emphasize is that the most important thing to us is to be a part of the community, and to have our share of people's stories, and to have our own perspective.\\n\\nThe community does not mean what it says in the media, or in books or in the movies. It is the people who are there who share what they care about and who have a stake in the world and are part of our community.\\n\\nThe people who are here who know what they are doing and who are willing to share that knowledge with us and with us in\"},\n",
       " {'generated_text': 'Hello, I am gregarious and I write a lot of articles. I also like to do a lot of social media.\\n\\nI hope you enjoy it.\\n\\nI do not ask for anything.'},\n",
       " {'generated_text': 'Hello, I am gregarious and a good person. I believe that I am the best person in the world. I have a family, I have a job, I have a house, I have a job. I love you, I love you and I love you even more. I love you more than I did when you were there. I love you more than I ever have. This is what I love about you, I love you more than I ever have.\\n\\nI am very happy with all the great things you have given me. I always have been a proud Christian. I am proud of the wonderful things you have provided me. I have been blessed to have been in a position where I am able to do a lot better than I have been able to do. I thank you for your love and support. I am very pleased that you are enjoying this journey. I hope that you continue to follow this journey and find the way to be happy and full of love.\\n\\nThank you very much. I hope that we can continue going on. I pray, you can say no more.\\n\\nSo what did you think of the news that your family and friends are coming to terms with the death of their son?\\n\\nWell, my husband and I are going to'},\n",
       " {'generated_text': \"Hello, I am gregarious and shy. I've never had a boyfriend but I love you and hope you fall in love with me. (Laughs) The last thing I want is for you to become a prostitute or something but I promise you that I will love you even more when you fall in love with me. (Laughs) I love you so much, and I'll be forever grateful.\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator=pipeline(\"text-generation\",model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I am greg\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe593705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "> Hello, I'm a language model, not a science. I'm a language designer. I want to write, I want to think. I want\n",
      "> Hello, I'm a language model, I use an English sentence structure, I like words over sentences.\n",
      "\n",
      "\"That's OK I'll look\n",
      "> Hello, I'm a language model, not just another language.\" This isn't a \"language model?\" It's an idea. So far, what\n",
      "> Hello, I'm a language model, not a programming model. I'm not a theoretical computer model - you read that right - because my ideas are\n",
      "> Hello, I'm a language model, I teach myself.\n",
      "\n",
      "I want to know more about how languages work and why they could be used.\n"
     ]
    }
   ],
   "source": [
    "from model import GPT\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tiktoken\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model=GPT.from_pretrained('gpt2').to(device) \n",
    "sequence_max=30\n",
    "n_sequence=5\n",
    "enc=tiktoken.get_encoding(\"gpt2\")\n",
    "tokens=enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens=torch.tensor(tokens,dtype=torch.long)\n",
    "tokens=tokens.unsqueeze(0).repeat(n_sequence,1)\n",
    "x=tokens.to(device)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "while x.size(1)< sequence_max:\n",
    "    with torch.no_grad():\n",
    "        logits,_=model(x)\n",
    "        logits=logits[:,-1,:]\n",
    "        prob=F.softmax(logits,dim=-1)\n",
    "        topk_probs,topk_indices=torch.topk(prob,50, dim=-1)\n",
    "\n",
    "        ix=torch.multinomial(topk_probs,1)\n",
    "\n",
    "        xcol=torch.gather(topk_indices,-1, ix)\n",
    "\n",
    "        x=torch.cat((x, xcol),dim=1)\n",
    "\n",
    "for i in range(n_sequence):\n",
    "    token=x[i,:sequence_max].tolist()\n",
    "    decoded=enc.decode(token)\n",
    "    print(\">\",decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a94d5561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model, not a science. I'm a language designer. I want to write, I want to think. I want\n",
      "> Hello, I'm a language model, I use an English sentence structure, I like words over sentences.\n",
      "\n",
      "\"That's OK I'll look\n",
      "> Hello, I'm a language model, not just another language.\" This isn't a \"language model?\" It's an idea. So far, what\n",
      "> Hello, I'm a language model, not a programming model. I'm not a theoretical computer model - you read that right - because my ideas are\n",
      "> Hello, I'm a language model, I teach myself.\n",
      "\n",
      "I want to know more about how languages work and why they could be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model2=GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "model2.eval()\n",
    "sequence_max=30\n",
    "n_sequence=5\n",
    "enc=tiktoken.get_encoding(\"gpt2\")\n",
    "tokens=enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens=torch.tensor(tokens,dtype=torch.long)\n",
    "tokens=tokens.unsqueeze(0).repeat(n_sequence,1)\n",
    "x=tokens.to(device)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "while x.size(1)< sequence_max:\n",
    "    with torch.no_grad():\n",
    "        logits=model2(x)[0]\n",
    "        logits=logits[:,-1,:]\n",
    "        prob=F.softmax(logits,dim=-1)\n",
    "        topk_probs,topk_indices=torch.topk(prob,50, dim=-1)\n",
    "\n",
    "        ix=torch.multinomial(topk_probs,1)\n",
    "\n",
    "        xcol=torch.gather(topk_indices,-1, ix)\n",
    "\n",
    "        x=torch.cat((x, xcol),dim=1)\n",
    "\n",
    "for i in range(n_sequence):\n",
    "    token=x[i,:sequence_max].tolist()\n",
    "    decoded=enc.decode(token)\n",
    "    print(\">\",decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538b4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
