{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c70c07",
   "metadata": {},
   "source": [
    "## We build the tokenizer and get into the very details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f3a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27573\n",
      "26122\n",
      "27494\n"
     ]
    }
   ],
   "source": [
    "# access unicode of a character\n",
    "print(ord(\"段\"))\n",
    "print(ord(\"昊\"))\n",
    "print(ord(\"武\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b107b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[230, 174, 181, 230, 152, 138, 230, 173, 166]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"段昊武\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ac1971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68, 97, 116, 97, 32, 105, 110, 116, 101, 103, 114, 97, 116, 105, 111, 110, 32, 109, 101, 116, 104, 111, 100, 115, 32, 111, 102, 102, 101, 114, 32, 97, 32, 114, 105, 99, 104, 32, 108, 97, 110, 100, 115, 99, 97, 112, 101, 32, 111, 102, 32, 116, 101, 99, 104, 110, 105, 113, 117, 101, 115, 44, 32, 102, 114, 111, 109, 32, 116, 114, 97, 100, 105, 116, 105, 111, 110, 97, 108, 32, 69, 84, 76, 32, 116, 111, 32, 109, 111, 100, 101, 114, 110, 44, 32, 114, 101, 97, 108, 45, 116, 105, 109, 101, 32, 97, 112, 112, 114, 111, 97, 99, 104, 101, 115, 32, 108, 105, 107, 101, 32, 100, 97, 116, 97, 32, 115, 116, 114, 101, 97, 109, 105, 110, 103, 32, 97, 110, 100, 32, 111, 110, 116, 111, 108, 111, 103, 121, 45, 98, 97, 115, 101, 100, 32, 105, 110, 116, 101, 103, 114, 97, 116, 105, 111, 110, 46, 32, 69, 97, 99, 104, 32, 109, 101, 116, 104, 111, 100, 32, 97, 100, 100, 114, 101, 115, 115, 101, 115, 32, 115, 112, 101, 99, 105, 102, 105, 99, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 115, 44, 32, 115, 117, 99, 104, 32, 97, 115, 32, 100, 97, 116, 97, 32, 118, 111, 108, 117, 109, 101, 44, 32, 114, 101, 97, 108, 45, 116, 105, 109, 101, 32, 110, 101, 101, 100, 115, 44, 32, 111, 114, 32, 115, 101, 109, 97, 110, 116, 105, 99, 32, 99, 111, 110, 102, 108, 105, 99, 116, 115, 44, 32, 119, 105, 116, 104, 32, 110, 111, 32, 111, 110, 101, 45, 115, 105, 122, 101, 45, 102, 105, 116, 115, 45, 97, 108, 108, 32, 115, 111, 108, 117, 116, 105, 111, 110, 46, 32, 84, 104, 101, 32, 108, 105, 115, 116, 101, 100, 32, 109, 101, 116, 104, 111, 100, 115, 32, 112, 114, 111, 118, 105, 100, 101, 32, 97, 32, 114, 111, 98, 117, 115, 116, 32, 102, 111, 117, 110, 100, 97, 116, 105, 111, 110, 32, 102, 111, 114, 32, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 105, 110, 103, 32, 97, 110, 100, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 105, 110, 103, 32, 100, 97, 116, 97, 32, 105, 110, 116, 101, 103, 114, 97, 116, 105, 111, 110, 44, 32, 99, 97, 116, 101, 114, 105, 110, 103, 32, 116, 111, 32, 98, 111, 116, 104, 32, 112, 114, 97, 99, 116, 105, 99, 97, 108, 32, 97, 110, 100, 32, 116, 104, 101, 111, 114, 101, 116, 105, 99, 97, 108, 32, 105, 110, 116, 101, 114, 101, 115, 116, 115, 46, 32, 87, 104, 101, 116, 104, 101, 114, 32, 121, 111, 117, 39, 114, 101, 32, 99, 101, 110, 116, 114, 97, 108, 105, 122, 105, 110, 103, 32, 100, 97, 116, 97, 32, 105, 110, 32, 97, 32, 119, 97, 114, 101, 104, 111, 117, 115, 101, 32, 111, 114, 32, 114, 101, 115, 111, 108, 118, 105, 110, 103, 32, 115, 101, 109, 97, 110, 116, 105, 99, 32, 109, 101, 97, 110, 105, 110, 103, 115, 32, 119, 105, 116, 104, 32, 111, 110, 116, 111, 108, 111, 103, 105, 101, 115, 44, 32, 116, 104, 101, 115, 101, 32, 114, 101, 115, 111, 117, 114, 99, 101, 115, 32, 101, 110, 115, 117, 114, 101, 32, 97, 32, 99, 111, 109, 112, 114, 101, 104, 101, 110, 115, 105, 118, 101, 32, 97, 112, 112, 114, 111, 97, 99, 104, 32, 116, 111, 32, 109, 97, 110, 97, 103, 105, 110, 103, 32, 104, 101, 116, 101, 114, 111, 103, 101, 110, 101, 111, 117, 115, 32, 100, 97, 116, 97, 32, 115, 111, 117, 114, 99, 101, 115, 46]\n",
      "645\n"
     ]
    }
   ],
   "source": [
    "# the byte-pairing encoding algorithm\n",
    "# find the byte pair with the highest frequency\n",
    "# replace it with a new byte\n",
    "# repeat until the vocabulary size is reached\n",
    "# the vocabulary size is the number of unique characters\n",
    "\n",
    "text=\"Data integration methods offer a rich landscape of techniques, from traditional ETL to modern, real-time approaches like data streaming and ontology-based integration. Each method addresses specific challenges, such as data volume, real-time needs, or semantic conflicts, with no one-size-fits-all solution. The listed methods provide a robust foundation for understanding and implementing data integration, catering to both practical and theoretical interests. Whether you're centralizing data in a warehouse or resolving semantic meanings with ontologies, these resources ensure a comprehensive approach to managing heterogeneous data sources.\"\n",
    "tokens=list(text.encode(\"utf-8\"))\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44cdbecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(68, 97): 1, (97, 116): 11, (116, 97): 7, (97, 32): 10, (32, 105): 6, (105, 110): 13, (110, 116): 10, (116, 101): 8, (101, 103): 3, (103, 114): 3, (114, 97): 6, (116, 105): 13, (105, 111): 6, (111, 110): 10, (110, 32): 3, (32, 109): 6, (109, 101): 8, (101, 116): 6, (116, 104): 9, (104, 111): 4, (111, 100): 4, (100, 115): 4, (115, 32): 8, (32, 111): 7, (111, 102): 2, (102, 102): 1, (102, 101): 1, (101, 114): 7, (114, 32): 5, (32, 97): 11, (32, 114): 6, (114, 105): 2, (105, 99): 7, (99, 104): 7, (104, 32): 7, (32, 108): 3, (108, 97): 1, (97, 110): 9, (110, 100): 7, (115, 99): 1, (99, 97): 4, (97, 112): 3, (112, 101): 2, (101, 32): 11, (102, 32): 1, (32, 116): 7, (101, 99): 2, (104, 110): 1, (110, 105): 2, (105, 113): 1, (113, 117): 1, (117, 101): 1, (101, 115): 12, (115, 44): 5, (44, 32): 8, (32, 102): 3, (102, 114): 1, (114, 111): 6, (111, 109): 2, (109, 32): 1, (116, 114): 3, (97, 100): 2, (100, 105): 2, (105, 116): 4, (110, 97): 2, (97, 108): 8, (108, 32): 4, (32, 69): 2, (69, 84): 1, (84, 76): 1, (76, 32): 1, (116, 111): 5, (111, 32): 4, (109, 111): 1, (100, 101): 3, (114, 110): 1, (110, 44): 2, (114, 101): 12, (101, 97): 4, (108, 45): 2, (45, 116): 2, (105, 109): 3, (112, 112): 2, (112, 114): 5, (111, 97): 2, (97, 99): 4, (104, 101): 8, (108, 105): 4, (105, 107): 1, (107, 101): 1, (32, 100): 5, (100, 97): 6, (32, 115): 7, (115, 116): 5, (97, 109): 1, (109, 105): 1, (110, 103): 9, (103, 32): 7, (100, 32): 6, (111, 108): 5, (108, 111): 2, (111, 103): 3, (103, 121): 1, (121, 45): 1, (45, 98): 1, (98, 97): 1, (97, 115): 2, (115, 101): 6, (101, 100): 3, (110, 46): 2, (46, 32): 3, (69, 97): 1, (100, 100): 1, (100, 114): 1, (115, 115): 1, (115, 112): 1, (99, 105): 1, (105, 102): 1, (102, 105): 2, (99, 32): 3, (32, 99): 5, (104, 97): 1, (108, 108): 2, (108, 101): 2, (101, 110): 6, (103, 101): 2, (115, 117): 2, (117, 99): 1, (32, 118): 1, (118, 111): 1, (108, 117): 2, (117, 109): 1, (101, 44): 1, (32, 110): 2, (110, 101): 3, (101, 101): 1, (111, 114): 4, (101, 109): 3, (109, 97): 3, (99, 111): 2, (110, 102): 1, (102, 108): 1, (99, 116): 2, (116, 115): 3, (32, 119): 3, (119, 105): 2, (110, 111): 1, (101, 45): 2, (45, 115): 1, (115, 105): 2, (105, 122): 2, (122, 101): 1, (45, 102): 1, (115, 45): 1, (45, 97): 1, (115, 111): 4, (117, 116): 1, (32, 84): 1, (84, 104): 1, (105, 115): 1, (32, 112): 2, (111, 118): 1, (118, 105): 2, (105, 100): 1, (111, 98): 1, (98, 117): 1, (117, 115): 3, (116, 32): 1, (102, 111): 2, (111, 117): 6, (117, 110): 2, (32, 117): 1, (114, 115): 1, (109, 112): 2, (112, 108): 1, (32, 98): 1, (98, 111): 1, (111, 116): 1, (101, 111): 2, (115, 46): 2, (32, 87): 1, (87, 104): 1, (32, 121): 1, (121, 111): 1, (117, 39): 1, (39, 114): 1, (99, 101): 3, (122, 105): 1, (119, 97): 1, (97, 114): 1, (101, 104): 2, (108, 118): 1, (103, 115): 1, (103, 105): 2, (105, 101): 1, (117, 114): 3, (114, 99): 2, (32, 101): 1, (110, 115): 2, (105, 118): 1, (118, 101): 1, (97, 103): 1, (32, 104): 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((105, 110), 13),\n",
       " ((116, 105), 13),\n",
       " ((101, 115), 12),\n",
       " ((114, 101), 12),\n",
       " ((97, 116), 11),\n",
       " ((32, 97), 11),\n",
       " ((101, 32), 11),\n",
       " ((97, 32), 10),\n",
       " ((110, 116), 10),\n",
       " ((111, 110), 10),\n",
       " ((116, 104), 9),\n",
       " ((97, 110), 9),\n",
       " ((110, 103), 9),\n",
       " ((116, 101), 8),\n",
       " ((109, 101), 8),\n",
       " ((115, 32), 8),\n",
       " ((44, 32), 8),\n",
       " ((97, 108), 8),\n",
       " ((104, 101), 8),\n",
       " ((116, 97), 7),\n",
       " ((32, 111), 7),\n",
       " ((101, 114), 7),\n",
       " ((105, 99), 7),\n",
       " ((99, 104), 7),\n",
       " ((104, 32), 7),\n",
       " ((110, 100), 7),\n",
       " ((32, 116), 7),\n",
       " ((32, 115), 7),\n",
       " ((103, 32), 7),\n",
       " ((32, 105), 6),\n",
       " ((114, 97), 6),\n",
       " ((105, 111), 6),\n",
       " ((32, 109), 6),\n",
       " ((101, 116), 6),\n",
       " ((32, 114), 6),\n",
       " ((114, 111), 6),\n",
       " ((100, 97), 6),\n",
       " ((100, 32), 6),\n",
       " ((115, 101), 6),\n",
       " ((101, 110), 6),\n",
       " ((111, 117), 6),\n",
       " ((114, 32), 5),\n",
       " ((115, 44), 5),\n",
       " ((116, 111), 5),\n",
       " ((112, 114), 5),\n",
       " ((32, 100), 5),\n",
       " ((115, 116), 5),\n",
       " ((111, 108), 5),\n",
       " ((32, 99), 5),\n",
       " ((104, 111), 4),\n",
       " ((111, 100), 4),\n",
       " ((100, 115), 4),\n",
       " ((99, 97), 4),\n",
       " ((105, 116), 4),\n",
       " ((108, 32), 4),\n",
       " ((111, 32), 4),\n",
       " ((101, 97), 4),\n",
       " ((97, 99), 4),\n",
       " ((108, 105), 4),\n",
       " ((111, 114), 4),\n",
       " ((115, 111), 4),\n",
       " ((101, 103), 3),\n",
       " ((103, 114), 3),\n",
       " ((110, 32), 3),\n",
       " ((32, 108), 3),\n",
       " ((97, 112), 3),\n",
       " ((32, 102), 3),\n",
       " ((116, 114), 3),\n",
       " ((100, 101), 3),\n",
       " ((105, 109), 3),\n",
       " ((111, 103), 3),\n",
       " ((101, 100), 3),\n",
       " ((46, 32), 3),\n",
       " ((99, 32), 3),\n",
       " ((110, 101), 3),\n",
       " ((101, 109), 3),\n",
       " ((109, 97), 3),\n",
       " ((116, 115), 3),\n",
       " ((32, 119), 3),\n",
       " ((117, 115), 3),\n",
       " ((99, 101), 3),\n",
       " ((117, 114), 3),\n",
       " ((111, 102), 2),\n",
       " ((114, 105), 2),\n",
       " ((112, 101), 2),\n",
       " ((101, 99), 2),\n",
       " ((110, 105), 2),\n",
       " ((111, 109), 2),\n",
       " ((97, 100), 2),\n",
       " ((100, 105), 2),\n",
       " ((110, 97), 2),\n",
       " ((32, 69), 2),\n",
       " ((110, 44), 2),\n",
       " ((108, 45), 2),\n",
       " ((45, 116), 2),\n",
       " ((112, 112), 2),\n",
       " ((111, 97), 2),\n",
       " ((108, 111), 2),\n",
       " ((97, 115), 2),\n",
       " ((110, 46), 2),\n",
       " ((102, 105), 2),\n",
       " ((108, 108), 2),\n",
       " ((108, 101), 2),\n",
       " ((103, 101), 2),\n",
       " ((115, 117), 2),\n",
       " ((108, 117), 2),\n",
       " ((32, 110), 2),\n",
       " ((99, 111), 2),\n",
       " ((99, 116), 2),\n",
       " ((119, 105), 2),\n",
       " ((101, 45), 2),\n",
       " ((115, 105), 2),\n",
       " ((105, 122), 2),\n",
       " ((32, 112), 2),\n",
       " ((118, 105), 2),\n",
       " ((102, 111), 2),\n",
       " ((117, 110), 2),\n",
       " ((109, 112), 2),\n",
       " ((101, 111), 2),\n",
       " ((115, 46), 2),\n",
       " ((101, 104), 2),\n",
       " ((103, 105), 2),\n",
       " ((114, 99), 2),\n",
       " ((110, 115), 2),\n",
       " ((68, 97), 1),\n",
       " ((102, 102), 1),\n",
       " ((102, 101), 1),\n",
       " ((108, 97), 1),\n",
       " ((115, 99), 1),\n",
       " ((102, 32), 1),\n",
       " ((104, 110), 1),\n",
       " ((105, 113), 1),\n",
       " ((113, 117), 1),\n",
       " ((117, 101), 1),\n",
       " ((102, 114), 1),\n",
       " ((109, 32), 1),\n",
       " ((69, 84), 1),\n",
       " ((84, 76), 1),\n",
       " ((76, 32), 1),\n",
       " ((109, 111), 1),\n",
       " ((114, 110), 1),\n",
       " ((105, 107), 1),\n",
       " ((107, 101), 1),\n",
       " ((97, 109), 1),\n",
       " ((109, 105), 1),\n",
       " ((103, 121), 1),\n",
       " ((121, 45), 1),\n",
       " ((45, 98), 1),\n",
       " ((98, 97), 1),\n",
       " ((69, 97), 1),\n",
       " ((100, 100), 1),\n",
       " ((100, 114), 1),\n",
       " ((115, 115), 1),\n",
       " ((115, 112), 1),\n",
       " ((99, 105), 1),\n",
       " ((105, 102), 1),\n",
       " ((104, 97), 1),\n",
       " ((117, 99), 1),\n",
       " ((32, 118), 1),\n",
       " ((118, 111), 1),\n",
       " ((117, 109), 1),\n",
       " ((101, 44), 1),\n",
       " ((101, 101), 1),\n",
       " ((110, 102), 1),\n",
       " ((102, 108), 1),\n",
       " ((110, 111), 1),\n",
       " ((45, 115), 1),\n",
       " ((122, 101), 1),\n",
       " ((45, 102), 1),\n",
       " ((115, 45), 1),\n",
       " ((45, 97), 1),\n",
       " ((117, 116), 1),\n",
       " ((32, 84), 1),\n",
       " ((84, 104), 1),\n",
       " ((105, 115), 1),\n",
       " ((111, 118), 1),\n",
       " ((105, 100), 1),\n",
       " ((111, 98), 1),\n",
       " ((98, 117), 1),\n",
       " ((116, 32), 1),\n",
       " ((32, 117), 1),\n",
       " ((114, 115), 1),\n",
       " ((112, 108), 1),\n",
       " ((32, 98), 1),\n",
       " ((98, 111), 1),\n",
       " ((111, 116), 1),\n",
       " ((32, 87), 1),\n",
       " ((87, 104), 1),\n",
       " ((32, 121), 1),\n",
       " ((121, 111), 1),\n",
       " ((117, 39), 1),\n",
       " ((39, 114), 1),\n",
       " ((122, 105), 1),\n",
       " ((119, 97), 1),\n",
       " ((97, 114), 1),\n",
       " ((108, 118), 1),\n",
       " ((103, 115), 1),\n",
       " ((105, 101), 1),\n",
       " ((32, 101), 1),\n",
       " ((105, 118), 1),\n",
       " ((118, 101), 1),\n",
       " ((97, 103), 1),\n",
       " ((32, 104), 1)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we first need a function to count the frequency of each byte pair\n",
    "# we first build the pair frequency dictionary\n",
    "\n",
    "def get_stats(tokens):\n",
    "    pairs={}\n",
    "    for i in range(len(tokens)-1):\n",
    "        pair=(tokens[i], tokens[i+1])\n",
    "        if pair in pairs:\n",
    "            pairs[pair]+=1\n",
    "        else:\n",
    "            pairs[pair]=1\n",
    "\n",
    "    return pairs        \n",
    "\n",
    "stats=get_stats(tokens)  \n",
    "print(stats)   \n",
    "sorted(list(stats.items()), key=lambda x: x[1], reverse=True) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61945ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', 'n')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(105), chr(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51345df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 110)\n"
     ]
    }
   ],
   "source": [
    "#alternatively \n",
    "top_pair=max(stats, key=stats.get)\n",
    "print(top_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85a31a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to write a function to merge the most frequent pair into a new toke  \n",
    "ids=list(tokens)\n",
    "def merge(tokens, pair, new_token):\n",
    "    # new list of tokens with pair merged \n",
    "    new_tokens=[]\n",
    "    i=0\n",
    "    while i< len(tokens):\n",
    "        # if the current token and the next token form the pair, we merge them\n",
    "        if i< len(tokens)-1 and tokens[i]==pair[0] and tokens[i+1]==pair[1]:\n",
    "            new_tokens.append(new_token)\n",
    "            i+=2\n",
    "        else:\n",
    "            new_tokens.append(tokens[i])\n",
    "            i+=1\n",
    "    return new_tokens            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3eb8ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "vocab_size=len(list(set(tokens)))\n",
    "vocab_size_merged=vocab_size+ 20\n",
    "print(vocab_size)\n",
    "print(vocab_size_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6433eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "# Because we are playing with the tokenier, we first find the maxiam token\n",
    "max_token=max(tokens)\n",
    "print(max_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab2e7252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging(105, 110) into new token 123\n",
      "merging(116, 105) into new token 124\n",
      "merging(101, 115) into new token 125\n",
      "merging(32, 97) into new token 126\n",
      "merging(111, 110) into new token 127\n",
      "merging(116, 104) into new token 128\n",
      "merging(116, 101) into new token 129\n",
      "merging(109, 101) into new token 130\n",
      "merging(44, 32) into new token 131\n",
      "merging(97, 108) into new token 132\n",
      "merging(114, 101) into new token 133\n",
      "merging(123, 103) into new token 134\n",
      "merging(116, 97) into new token 135\n",
      "merging(99, 104) into new token 136\n",
      "merging(110, 100) into new token 137\n",
      "merging(97, 135) into new token 138\n",
      "merging(138, 32) into new token 139\n",
      "merging(124, 127) into new token 140\n",
      "merging(114, 111) into new token 141\n",
      "merging(111, 117) into new token 142\n"
     ]
    }
   ],
   "source": [
    "# our new emerged token will start at 123\n",
    "\n",
    "merges={}\n",
    "for i in range(vocab_size, vocab_size_merged):\n",
    "    stats=get_stats(tokens)    \n",
    "    pair=max(stats,key=stats.get)\n",
    "    max_token=max(tokens)\n",
    "    print(f\"merging{pair} into new token {max_token+1}\")  #sorted(list(stats.items()), key=lambda x: x[1], reverse=True) \n",
    "    tokens=merge(tokens, pair, max_token+1)\n",
    "    # keep track of the merged history\n",
    "    merges[pair]=max_token+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "024d3c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(105, 110): 123, (116, 105): 124, (101, 115): 125, (32, 97): 126, (111, 110): 127, (116, 104): 128, (116, 101): 129, (109, 101): 130, (44, 32): 131, (97, 108): 132, (114, 101): 133, (123, 103): 134, (116, 97): 135, (99, 104): 136, (110, 100): 137, (97, 135): 138, (138, 32): 139, (124, 127): 140, (114, 111): 141, (111, 117): 142}\n"
     ]
    }
   ],
   "source": [
    "print(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4adc9b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "645\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7cd238",
   "metadata": {},
   "source": [
    "we have about 645/479=1.34 compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding will be require reverse the merged history\n",
    "# we need this to turn the prediction of the model into the string in the vocabulary \n",
    "# we first need to create a updated vocabulary\n",
    "vocab={id:bytes([id]) for id in range(max(ids))}\n",
    "for (p0, p1), id in merges.items():\n",
    "    # we need to update the vocabulary with the new token\n",
    "    vocab[id]=vocab[p0]+ vocab[p1]\n",
    "\n",
    "\n",
    "def decode(tokens):\n",
    "\n",
    "    tokens_bytes=b\"\".join(vocab[i] for i in tokens)\n",
    "    text=tokens_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d206943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    tokens=list(text.encode(\"utf-8\"))\n",
    "    # we need to start with the tokens that got merged early in the process \n",
    "    while len(tokens)>2:\n",
    "        stats=get_stats(tokens)\n",
    "        pair=min(stats, key=lambda p: merges.get(p, float(\"inf\")) )\n",
    "        if pair not in merges:\n",
    "            break\n",
    "        new_token=merges[pair]\n",
    "        tokens=merge(tokens,pair, new_token)\n",
    "    return tokens    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6cc78071",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"Data integration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1080324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test2=decode(encode(test))\n",
    "print(test==test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8adf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for our actual project, we will use tokenizer from open ai\n",
    "import tiktoken\n",
    "\n",
    "# another package that one can use is sentencepiece, which is used ba Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b7a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
